#!/bin/bash
# SCRIPT D'INSTALLATION PIPELINE LOGSTASH CORRIGÃ‰
# Compatible avec les formats de logs honeypot rÃ©els
# VM ELK: 192.168.2.124
# Date: 2025-06-30

GREEN='\033[0;32m'
YELLOW='\033[1;33m'
RED='\033[0;31m'
BLUE='\033[0;34m'
NC='\033[0m'

print_status() { echo -e "${GREEN}[+] $1${NC}"; }
print_warning() { echo -e "${YELLOW}[!] $1${NC}"; }
print_error() { echo -e "${RED}[-] $1${NC}"; }
print_info() { echo -e "${BLUE}[i] $1${NC}"; }

if [ "$EUID" -ne 0 ]; then
    print_error "Ce script doit Ãªtre exÃ©cutÃ© en tant que root"
    exit 1
fi

print_status "=== INSTALLATION PIPELINE LOGSTASH CORRIGÃ‰ ==="
echo ""
print_info "Ce script va remplacer vos pipelines actuels par une version"
print_info "parfaitement adaptÃ©e Ã  vos formats de logs Cowrie et HTTP"
echo ""

# =============================================================================
# 1. VÃ‰RIFICATIONS PRÃ‰ALABLES
# =============================================================================

print_status "1. VÃ©rifications prÃ©alables..."

# VÃ©rifier Elasticsearch
if ! curl -s "http://192.168.2.124:9200/_cluster/health" >/dev/null 2>&1; then
    print_error "Elasticsearch non accessible sur 192.168.2.124:9200"
    exit 1
fi

# VÃ©rifier Logstash installÃ©
if ! command -v /usr/share/logstash/bin/logstash >/dev/null 2>&1; then
    print_error "Logstash non installÃ©"
    exit 1
fi

# VÃ©rifier que jq est disponible
if ! command -v jq >/dev/null 2>&1; then
    print_warning "jq non installÃ© - Installation..."
    apt-get update && apt-get install -y jq
fi

print_status "âœ… PrÃ©requis validÃ©s"

# =============================================================================
# 2. ARRÃŠT SÃ‰CURISÃ‰ DE LOGSTASH
# =============================================================================

print_status "2. ArrÃªt sÃ©curisÃ© de Logstash..."
systemctl stop logstash 2>/dev/null || true

# Attendre l'arrÃªt complet
sleep 5

# VÃ©rifier que Logstash est bien arrÃªtÃ©
if pgrep -f logstash >/dev/null; then
    print_warning "Logstash encore actif - Force kill..."
    pkill -9 -f logstash
    sleep 2
fi

print_status "âœ… Logstash arrÃªtÃ©"

# =============================================================================
# 3. SAUVEGARDE DES CONFIGURATIONS EXISTANTES
# =============================================================================

print_status "3. Sauvegarde des configurations existantes..."

BACKUP_DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_DIR="/opt/logstash-backups/pipeline-correction-$BACKUP_DATE"

mkdir -p "$BACKUP_DIR"

if [ -d "/etc/logstash/conf.d" ] && [ "$(ls -A /etc/logstash/conf.d)" ]; then
    cp -r /etc/logstash/conf.d/* "$BACKUP_DIR/" 2>/dev/null || true
    print_info "Sauvegarde crÃ©Ã©e : $BACKUP_DIR"
    
    # Lister les fichiers sauvegardÃ©s
    print_info "Fichiers sauvegardÃ©s :"
    ls -la "$BACKUP_DIR/"
else
    print_warning "Aucune configuration existante trouvÃ©e"
fi

# =============================================================================
# 4. NETTOYAGE ET PRÃ‰PARATION
# =============================================================================

print_status "4. Nettoyage des anciennes configurations..."

# Supprimer tous les fichiers de configuration
rm -f /etc/logstash/conf.d/*.conf

# CrÃ©er le rÃ©pertoire s'il n'existe pas
mkdir -p /etc/logstash/conf.d

print_status "âœ… RÃ©pertoire nettoyÃ©"

# =============================================================================
# 5. INSTALLATION DE LA NOUVELLE CONFIGURATION
# =============================================================================

print_status "5. Installation de la nouvelle configuration adaptÃ©e..."

cat > /etc/logstash/conf.d/00-honeypot-pipelines-corrected.conf << 'EOF'
# =============================================================================
# PIPELINE LOGSTASH CORRIGÃ‰ POUR DONNÃ‰ES HONEYPOT RÃ‰ELLES
# Compatible avec le nouveau sender et les formats de logs exacts
# =============================================================================

input {
  tcp {
    port => 5046
    host => "0.0.0.0"
    codec => json
    type => "honeypot_tcp"
  }
}

filter {
  # MÃ©tadonnÃ©es communes
  mutate {
    add_field => { "[@metadata][processed_by]" => "logstash" }
    add_field => { "[@metadata][processing_timestamp]" => "%{@timestamp}" }
  }

  # ==========================================================================
  # PIPELINE COWRIE SSH - ADAPTÃ‰ AUX DONNÃ‰ES RÃ‰ELLES
  # ==========================================================================
  if [honeypot_type] == "ssh" {
    # Les donnÃ©es arrivent maintenant directement au niveau racine
    
    # Parse du timestamp Cowrie (format: 2025-06-27T13:47:54.424222Z)
    if [timestamp] {
      date {
        match => [ "timestamp", "ISO8601" ]
        target => "cowrie_timestamp"
      }
    }
    
    # Enrichissement GeoIP sur src_ip
    if [src_ip] and [src_ip] != "127.0.0.1" and [src_ip] != "192.168.2.117" {
      geoip {
        source => "src_ip"
        target => "geoip"
        add_field => { "src_country" => "%{[geoip][country_name]}" }
        add_field => { "src_city" => "%{[geoip][city_name]}" }
        add_field => { "src_coordinates" => "%{[geoip][latitude]},%{[geoip][longitude]}" }
      }
    }
    
    # Classification basÃ©e sur l'eventid rÃ©el de Cowrie
    if [eventid] {
      if [eventid] == "cowrie.login.success" {
        mutate { 
          add_field => { "event_category" => "authentication_success" }
          add_field => { "severity_level" => "critical" }
          add_field => { "alert_score" => "10" }
          add_field => { "mitre_tactic" => "initial_access" }
          add_field => { "mitre_technique" => "T1078" }
        }
      } else if [eventid] == "cowrie.login.failed" {
        mutate { 
          add_field => { "event_category" => "authentication_failure" }
          add_field => { "severity_level" => "medium" }
          add_field => { "alert_score" => "5" }
          add_field => { "mitre_tactic" => "credential_access" }
          add_field => { "mitre_technique" => "T1110" }
        }
      } else if [eventid] == "cowrie.command.input" {
        mutate { 
          add_field => { "event_category" => "command_execution" }
          add_field => { "severity_level" => "high" }
          add_field => { "alert_score" => "8" }
          add_field => { "mitre_tactic" => "execution" }
          add_field => { "mitre_technique" => "T1059" }
        }
      } else if [eventid] == "cowrie.session.connect" {
        mutate { 
          add_field => { "event_category" => "connection" }
          add_field => { "severity_level" => "low" }
          add_field => { "alert_score" => "3" }
          add_field => { "mitre_tactic" => "initial_access" }
        }
      } else if [eventid] == "cowrie.session.closed" {
        mutate { 
          add_field => { "event_category" => "disconnection" }
          add_field => { "severity_level" => "low" }
          add_field => { "alert_score" => "1" }
        }
      } else if [eventid] == "cowrie.client.version" {
        mutate { 
          add_field => { "event_category" => "reconnaissance" }
          add_field => { "severity_level" => "low" }
          add_field => { "alert_score" => "2" }
        }
      }
    }
    
    # Analyser les commandes suspectes dans le message
    if [message] {
      if [message] =~ /(?i)(wget|curl).*http/ {
        mutate { 
          add_field => { "suspicious_command" => "true" }
          add_field => { "command_type" => "download_tool" }
          add_field => { "alert_score" => "9" }
          add_field => { "mitre_technique" => "T1105" }
        }
      }
      
      if [message] =~ /(?i)(nc|netcat|nmap)/ {
        mutate { 
          add_field => { "suspicious_command" => "true" }
          add_field => { "command_type" => "network_tool" }
          add_field => { "alert_score" => "8" }
        }
      }
      
      if [message] =~ /(?i)(rm -rf|dd if=|mkfs|fdisk)/ {
        mutate { 
          add_field => { "suspicious_command" => "true" }
          add_field => { "command_type" => "destructive" }
          add_field => { "alert_score" => "10" }
        }
      }
      
      if [message] =~ /(?i)(cat|less|more).*(passwd|shadow|hosts)/ {
        mutate { 
          add_field => { "suspicious_command" => "true" }
          add_field => { "command_type" => "reconnaissance" }
          add_field => { "alert_score" => "7" }
          add_field => { "mitre_technique" => "T1082" }
        }
      }
    }
    
    # Ajouter des mÃ©tadonnÃ©es de service
    mutate {
      add_field => { "service_type" => "ssh_honeypot" }
      add_field => { "infrastructure" => "honeypot" }
    }
  }

  # ==========================================================================
  # PIPELINE HTTP HONEYPOT - ADAPTÃ‰ AUX DONNÃ‰ES RÃ‰ELLES
  # ==========================================================================
  else if [honeypot_type] == "http" {
    
    # Parse du timestamp HTTP (format: 2025-05-07T16:28:49.324)
    if [timestamp] {
      date {
        match => [ "timestamp", "yyyy-MM-dd'T'HH:mm:ss.SSS" ]
        target => "http_timestamp"
      }
    }
    
    # Enrichissement GeoIP sur le champ ip
    if [ip] and [ip] != "127.0.0.1" and [ip] != "192.168.2.117" {
      geoip {
        source => "ip"
        target => "geoip"
        add_field => { "src_country" => "%{[geoip][country_name]}" }
        add_field => { "src_city" => "%{[geoip][city_name]}" }
        add_field => { "src_coordinates" => "%{[geoip][latitude]},%{[geoip][longitude]}" }
      }
    }
    
    # Classification basÃ©e sur attack_type rÃ©el
    if [attack_type] {
      if [attack_type] == "sql_injection" {
        mutate { 
          add_field => { "event_category" => "web_attack" }
          add_field => { "attack_category" => "injection" }
          add_field => { "owasp_category" => "A03_injection" }
          add_field => { "mitre_technique" => "T1190" }
        }
      } else if [attack_type] == "sql_error" {
        mutate { 
          add_field => { "event_category" => "web_error" }
          add_field => { "attack_category" => "information_disclosure" }
          add_field => { "owasp_category" => "A01_broken_access" }
        }
      } else if [attack_type] == "api_access" {
        mutate { 
          add_field => { "event_category" => "api_access" }
          add_field => { "attack_category" => "reconnaissance" }
        }
      }
    }
    
    # Analyser les query_string suspectes
    if [query_string] {
      if [query_string] =~ /(?i)(union|select|insert|delete|drop|exec|script)/ {
        mutate { 
          add_field => { "suspicious_query" => "true" }
          add_field => { "attack_vector" => "sql_injection" }
        }
      }
      
      if [query_string] =~ /(?i)(<script|javascript|onerror|onload)/ {
        mutate { 
          add_field => { "suspicious_query" => "true" }
          add_field => { "attack_vector" => "xss" }
          add_field => { "owasp_category" => "A07_xss" }
        }
      }
      
      if [query_string] =~ /(?i)(\.\.\/|\.\.\\|etc\/passwd|boot\.ini)/ {
        mutate { 
          add_field => { "suspicious_query" => "true" }
          add_field => { "attack_vector" => "path_traversal" }
        }
      }
    }
    
    # Analyser les User-Agent suspects
    if [user_agent] {
      if [user_agent] =~ /(?i)(sqlmap|burp|nmap|nikto|dirb|gobuster)/ {
        mutate { 
          add_field => { "suspicious_useragent" => "true" }
          add_field => { "scanner_detected" => "true" }
        }
      }
      
      if [user_agent] =~ /(?i)(bot|crawler|spider|scan)/ {
        mutate { 
          add_field => { "automated_tool" => "true" }
        }
      }
    }
    
    # Classification de sÃ©vÃ©ritÃ©
    if [severity] {
      if [severity] == "critical" {
        mutate { add_field => { "alert_score" => "10" } }
      } else if [severity] == "high" {
        mutate { add_field => { "alert_score" => "8" } }
      } else if [severity] == "medium" {
        mutate { add_field => { "alert_score" => "5" } }
      } else if [severity] == "low" {
        mutate { add_field => { "alert_score" => "2" } }
      }
    }
    
    # MÃ©tadonnÃ©es de service
    mutate {
      add_field => { "service_type" => "http_honeypot" }
      add_field => { "infrastructure" => "honeypot" }
    }
  }

  # ==========================================================================
  # PIPELINE FTP HONEYPOT - GARDE LA LOGIQUE EXISTANTE
  # ==========================================================================
  else if [honeypot_type] == "ftp" {
    
    # Parse du timestamp selon le format
    if [timestamp] {
      date {
        match => [ "timestamp", "ISO8601" ]
        target => "ftp_timestamp"
      }
    }
    
    # Enrichissement GeoIP
    if [ip] and [ip] != "127.0.0.1" and [ip] != "192.168.2.117" {
      geoip {
        source => "ip"
        target => "geoip"
        add_field => { "src_country" => "%{[geoip][country_name]}" }
        add_field => { "src_city" => "%{[geoip][city_name]}" }
      }
    }
    
    # Classification basÃ©e sur les Ã©vÃ©nements FTP
    if [event_type] {
      if [event_type] == "auth_attempt" {
        if [success] == true {
          mutate { 
            add_field => { "event_category" => "authentication_success" }
            add_field => { "severity_level" => "critical" }
            add_field => { "alert_score" => "10" }
          }
        } else {
          mutate { 
            add_field => { "event_category" => "authentication_failure" }
            add_field => { "severity_level" => "medium" }
            add_field => { "alert_score" => "5" }
          }
        }
      } else if [event_type] == "file_upload" {
        mutate { 
          add_field => { "event_category" => "file_transfer" }
          add_field => { "severity_level" => "high" }
          add_field => { "alert_score" => "8" }
        }
      }
    }
    
    # DÃ©tection de fichiers suspects
    if [filename] {
      if [filename] =~ /(?i)(\.php|\.asp|\.exe|backdoor|shell|webshell)/ {
        mutate {
          add_field => { "suspicious_file" => "true" }
          add_field => { "malicious_file" => "true" }
          add_field => { "alert_score" => "10" }
        }
      }
    }
    
    mutate {
      add_field => { "service_type" => "ftp_honeypot" }
      add_field => { "infrastructure" => "honeypot" }
    }
  }

  # Normalisation finale pour tous les types
  if [honeypot_type] {
    # Copier l'IP source vers un champ unifiÃ©
    if [src_ip] and ![client_ip] {
      mutate { add_field => { "client_ip" => "%{src_ip}" } }
    } else if [ip] and ![client_ip] {
      mutate { add_field => { "client_ip" => "%{ip}" } }
    }
    
    # Ajouter un timestamp de traitement
    mutate {
      add_field => { "logstash_processed_at" => "%{@timestamp}" }
    }
    
    # Nettoyer les champs temporaires
    mutate {
      remove_field => [ "host", "port", "@version" ]
    }
  }
}

# =============================================================================
# OUTPUTS SPÃ‰CIALISÃ‰S PAR TYPE
# =============================================================================

output {
  # Output pour SSH Cowrie
  if [honeypot_type] == "ssh" {
    elasticsearch {
      hosts => ["192.168.2.124:9200"]
      index => "honeypot-cowrie-%{+YYYY.MM.dd}"
      template_name => "honeypot-cowrie"
    }
  }
  
  # Output pour HTTP
  else if [honeypot_type] == "http" {
    elasticsearch {
      hosts => ["192.168.2.124:9200"]
      index => "honeypot-http-%{+YYYY.MM.dd}"
      template_name => "honeypot-http"
    }
  }
  
  # Output pour FTP
  else if [honeypot_type] == "ftp" {
    elasticsearch {
      hosts => ["192.168.2.124:9200"]
      index => "honeypot-ftp-%{+YYYY.MM.dd}"
      template_name => "honeypot-ftp"
    }
  }
  
  # Fallback pour types non reconnus
  else {
    elasticsearch {
      hosts => ["192.168.2.124:9200"]
      index => "honeypot-misc-%{+YYYY.MM.dd}"
    }
  }
}
EOF

print_status "âœ… Nouvelle configuration installÃ©e"

# =============================================================================
# 6. CONFIGURATION DES PERMISSIONS
# =============================================================================

print_status "6. Configuration des permissions..."

chown -R logstash:logstash /etc/logstash/conf.d/
chmod 644 /etc/logstash/conf.d/*.conf

print_status "âœ… Permissions configurÃ©es"

# =============================================================================
# 7. TEST DE SYNTAXE
# =============================================================================

print_status "7. Test de syntaxe de la configuration..."

if sudo -u logstash /usr/share/logstash/bin/logstash --path.settings /etc/logstash -t; then
    print_status "âœ… Syntaxe validÃ©e avec succÃ¨s"
else
    print_error "âŒ Erreur de syntaxe dÃ©tectÃ©e"
    print_error "Restauration de l'ancienne configuration..."
    
    # Restaurer la sauvegarde
    rm -f /etc/logstash/conf.d/*.conf
    if [ -d "$BACKUP_DIR" ] && [ "$(ls -A $BACKUP_DIR)" ]; then
        cp "$BACKUP_DIR"/* /etc/logstash/conf.d/ 2>/dev/null || true
        print_warning "Configuration restaurÃ©e depuis $BACKUP_DIR"
    fi
    
    exit 1
fi

# =============================================================================
# 8. CONFIGURATION ELASTICSEARCH
# =============================================================================

print_status "8. Configuration d'Elasticsearch..."

# Configurer l'auto-crÃ©ation d'indices
curl -X PUT "http://192.168.2.124:9200/_cluster/settings" \
     -H "Content-Type: application/json" \
     -d '{
       "persistent": {
         "action.auto_create_index": "honeypot-*,logstash-*,filebeat-*,.monitoring-*"
       }
     }' >/dev/null 2>&1

if [ $? -eq 0 ]; then
    print_status "âœ… Elasticsearch configurÃ©"
else
    print_warning "âš ï¸ Impossible de configurer Elasticsearch"
fi

# =============================================================================
# 9. REDÃ‰MARRAGE DE LOGSTASH
# =============================================================================

print_status "9. RedÃ©marrage de Logstash..."

systemctl start logstash

# Attendre le dÃ©marrage avec timeout
print_info "Attente du dÃ©marrage (60s max)..."
counter=0
while [ $counter -lt 60 ]; do
    if systemctl is-active --quiet logstash; then
        print_status "âœ… Logstash dÃ©marrÃ© avec succÃ¨s"
        break
    fi
    
    if [ $((counter % 10)) -eq 0 ]; then
        echo "   Attente... ${counter}s"
    fi
    
    sleep 2
    counter=$((counter + 2))
done

if [ $counter -ge 60 ]; then
    print_error "âŒ Timeout - Logstash n'a pas dÃ©marrÃ©"
    print_error "VÃ©rifiez les logs : journalctl -u logstash -n 20"
    exit 1
fi

# =============================================================================
# 10. VÃ‰RIFICATIONS POST-INSTALLATION
# =============================================================================

print_status "10. VÃ©rifications post-installation..."

# VÃ©rifier le service
if systemctl is-active --quiet logstash; then
    print_status "âœ… Service Logstash actif"
else
    print_error "âŒ Service Logstash inactif"
fi

# VÃ©rifier le port TCP 5046 aprÃ¨s un dÃ©lai
sleep 10
if netstat -tlnp 2>/dev/null | grep -q ":5046 "; then
    print_status "âœ… Port TCP 5046 en Ã©coute"
else
    print_warning "âš ï¸ Port TCP 5046 pas encore ouvert (peut prendre du temps)"
fi

# Test de connectivitÃ© Elasticsearch
if curl -s "http://192.168.2.124:9200/_cluster/health" | grep -q "yellow\|green"; then
    print_status "âœ… Elasticsearch accessible"
else
    print_warning "âš ï¸ ProblÃ¨me avec Elasticsearch"
fi

# =============================================================================
# 11. CRÃ‰ATION D'OUTILS DE MONITORING
# =============================================================================

print_status "11. CrÃ©ation des outils de monitoring..."

# Script de monitoring principal
cat > /opt/monitor_honeypot_corrected.sh << 'MONITOR_EOF'
#!/bin/bash
echo "=== MONITORING PIPELINE HONEYPOT CORRIGÃ‰ ==="
echo "Date: $(date)"
echo ""

# Status du service
echo "ðŸ”§ SERVICE LOGSTASH:"
if systemctl is-active --quiet logstash; then
    echo "âœ… Service actif"
    uptime_info=$(systemctl show logstash --property=ActiveEnterTimestamp --value)
    echo "   DÃ©marrÃ©: $uptime_info"
else
    echo "âŒ Service inactif"
fi
echo ""

# Ports en Ã©coute
echo "ðŸ”Œ PORTS EN Ã‰COUTE:"
netstat -tlnp | grep -E ":5046|:9200|:9600" | while read line; do
    echo "   $line"
done
echo ""

# Indices Elasticsearch honeypot
echo "ðŸ“Š INDICES HONEYPOT:"
curl -s "http://192.168.2.124:9200/_cat/indices/honeypot-*?v&s=index" 2>/dev/null || echo "   Aucun indice honeypot trouvÃ©"
echo ""

# Comptage par type
echo "ðŸ”¢ DOCUMENTS PAR TYPE:"
for type in cowrie http ftp; do
    count=$(curl -s "http://192.168.2.124:9200/honeypot-$type-*/_count" 2>/dev/null | jq -r '.count // 0')
    echo "   honeypot-$type: $count documents"
done
echo ""

# DerniÃ¨res donnÃ©es
echo "ðŸ• DERNIÃˆRES DONNÃ‰ES REÃ‡UES:"
curl -s "http://192.168.2.124:9200/honeypot-*/_search?sort=@timestamp:desc&size=3&_source=honeypot_type,@timestamp,client_ip,eventid,attack_type" 2>/dev/null | \
jq -r '.hits.hits[]._source | "\(.@timestamp) - \(.honeypot_type) - \(.client_ip // "N/A") - \(.eventid // .attack_type // "N/A")"' 2>/dev/null || echo "   Aucune donnÃ©e rÃ©cente"
echo ""

# Stats pipeline Logstash
echo "ðŸ“ˆ STATISTIQUES PIPELINE:"
curl -s "http://192.168.2.124:9600/_node/stats/pipelines" 2>/dev/null | \
jq -r '.pipelines.main.events | "   Events: entrÃ©es=\(.in), sorties=\(.out), filtrÃ©s=\(.filtered)"' 2>/dev/null || echo "   Stats non disponibles"
echo ""

# DerniÃ¨res erreurs Logstash
echo "ðŸš¨ DERNIÃˆRES ERREURS:"
journalctl -u logstash --since "10 minutes ago" --no-pager | grep -i "error\|failed\|exception" | tail -3 || echo "   Aucune erreur rÃ©cente"
MONITOR_EOF

chmod +x /opt/monitor_honeypot_corrected.sh

# Script de test simple
cat > /opt/test_pipeline_corrected.sh << 'TEST_EOF'
#!/bin/bash
echo "=== TEST PIPELINE CORRIGÃ‰ ==="

LOGSTASH_HOST="192.168.2.124"
LOGSTASH_PORT="5046"

echo "1. Test connectivitÃ© TCP $LOGSTASH_PORT..."
if nc -z "$LOGSTASH_HOST" "$LOGSTASH_PORT" 2>/dev/null; then
    echo "âœ… Port accessible"
else
    echo "âŒ Port inaccessible"
    exit 1
fi

echo ""
echo "2. Envoi de logs de test..."

# Test Cowrie
cowrie_test='{"honeypot_type":"ssh","eventid":"cowrie.session.connect","src_ip":"192.168.1.100","timestamp":"2025-06-30T12:00:00.000Z","message":"Test connection","honeypot_service":"cowrie","source_vm":"192.168.2.117"}'

echo "   Test Cowrie SSH..."
echo "$cowrie_test" | nc -w 3 "$LOGSTASH_HOST" "$LOGSTASH_PORT"
if [ $? -eq 0 ]; then
    echo "   âœ… Cowrie envoyÃ©"
else
    echo "   âŒ Cowrie Ã©chouÃ©"
fi

# Test HTTP
http_test='{"honeypot_type":"http","attack_type":"sql_injection","ip":"192.168.1.101","timestamp":"2025-06-30T12:00:00.324","severity":"high","query_string":"SELECT * FROM users","honeypot_service":"main","source_vm":"192.168.2.117"}'

echo "   Test HTTP..."
echo "$http_test" | nc -w 3 "$LOGSTASH_HOST" "$LOGSTASH_PORT"
if [ $? -eq 0 ]; then
    echo "   âœ… HTTP envoyÃ©"
else
    echo "   âŒ HTTP Ã©chouÃ©"
fi

echo ""
echo "3. Attente du traitement (10s)..."
sleep 10

echo ""
echo "4. VÃ©rification dans Elasticsearch..."
curl -s "http://192.168.2.124:9200/honeypot-*/_search?q=Test&size=5&_source=honeypot_type,eventid,attack_type" 2>/dev/null | \
jq -r '.hits.hits[]._source | "   \(.honeypot_type): \(.eventid // .attack_type)"' 2>/dev/null || echo "   Erreur de recherche"

echo ""
echo "Test terminÃ© !"
TEST_EOF

chmod +x /opt/test_pipeline_corrected.sh

print_status "âœ… Outils de monitoring crÃ©Ã©s"

# =============================================================================
# 12. RÃ‰SUMÃ‰ FINAL
# =============================================================================

echo ""
print_status "=== INSTALLATION TERMINÃ‰E AVEC SUCCÃˆS ==="
echo ""

print_info "ðŸ“Š RÃ‰SUMÃ‰ DES ACTIONS:"
echo "âœ… Ancienne configuration sauvegardÃ©e: $BACKUP_DIR"
echo "âœ… Nouvelle configuration adaptÃ©e installÃ©e"
echo "âœ… Syntaxe validÃ©e avec succÃ¨s"
echo "âœ… Service Logstash redÃ©marrÃ©"
echo "âœ… Outils de monitoring crÃ©Ã©s"
echo ""

print_info "ðŸ“ FICHIERS INSTALLÃ‰S:"
echo "   â€¢ /etc/logstash/conf.d/00-honeypot-pipelines-corrected.conf"
echo "   â€¢ /opt/monitor_honeypot_corrected.sh (monitoring)"
echo "   â€¢ /opt/test_pipeline_corrected.sh (tests)"
echo ""

print_info "ðŸ”§ AMÃ‰LIORATIONS APPORTÃ‰ES:"
echo "   â€¢ Pipeline Cowrie adaptÃ© aux donnÃ©es rÃ©elles (eventid direct)"
echo "   â€¢ Pipeline HTTP pour attack_type, severity, query_string"
echo "   â€¢ Timestamps corrigÃ©s (ISO8601 + format HTTP)"
echo "   â€¢ Enrichissement GeoIP optimisÃ©"
echo "   â€¢ Classification MITRE ATT&CK et OWASP"
echo "   â€¢ Scoring d'alertes unifiÃ©"
echo ""

print_info "ðŸ“Š INDICES ELASTICSEARCH:"
echo "   â€¢ honeypot-cowrie-YYYY.MM.dd (donnÃ©es SSH)"
echo "   â€¢ honeypot-http-YYYY.MM.dd (attaques web)"
echo "   â€¢ honeypot-ftp-YYYY.MM.dd (transferts de fichiers)"
echo ""

print_warning "ðŸŽ¯ PROCHAINES Ã‰TAPES RECOMMANDÃ‰ES:"
echo ""
echo "1. Installer le nouveau sender honeypot:"
echo "   wget -O /tmp/honeypot_logs_sender_final.sh [URL_DU_SCRIPT]"
echo "   chmod +x /tmp/honeypot_logs_sender_final.sh"
echo "   systemctl stop honeypot-sender"
echo "   cp /tmp/honeypot_logs_sender_final.sh /opt/honeypot_logs_sender.sh"
echo "   systemctl start honeypot-sender"
echo ""

echo "2. Tester la configuration:"
echo "   /opt/test_pipeline_corrected.sh"
echo ""

echo "3. Monitoring en temps rÃ©el:"
echo "   /opt/monitor_honeypot_corrected.sh"
echo "   journalctl -u logstash -f"
echo ""

echo "4. VÃ©rifier les indices Elasticsearch:"
echo "   curl -s 'http://192.168.2.124:9200/_cat/indices/honeypot-*?v'"
echo ""

echo "5. GÃ©nÃ©rer du trafic de test:"
echo "   # Test SSH: ssh root@192.168.2.117 -p 2222"
echo "   # Test HTTP: curl 'http://192.168.2.117:8080/search?q=test'"
echo ""

print_info "ðŸ” COMMANDES DE DIAGNOSTIC:"
echo ""
echo "â€¢ VÃ©rifier Logstash:     systemctl status logstash"
echo "â€¢ Logs Logstash:         journalctl -u logstash -f"
echo "â€¢ Test syntaxe:          sudo -u logstash /usr/share/logstash/bin/logstash -t"
echo "â€¢ API Logstash:          curl http://192.168.2.124:9600/"
echo "â€¢ SantÃ© Elasticsearch:   curl http://192.168.2.124:9200/_cluster/health"
echo "â€¢ Monitoring pipeline:   /opt/monitor_honeypot_corrected.sh"
echo ""

print_info "ðŸ“‹ LOGS Ã€ SURVEILLER:"
echo "â€¢ Sender honeypot:       tail -f /var/log/honeypot-sender/sender.log"
echo "â€¢ Logstash service:      journalctl -u logstash -f"
echo "â€¢ Elasticsearch:         tail -f /var/log/elasticsearch/elasticsearch.log"
echo ""

print_warning "âš ï¸ EN CAS DE PROBLÃˆME:"
echo ""
echo "1. Restaurer l'ancienne config:"
echo "   systemctl stop logstash"
echo "   rm -f /etc/logstash/conf.d/*.conf"
echo "   cp $BACKUP_DIR/* /etc/logstash/conf.d/"
echo "   systemctl start logstash"
echo ""

echo "2. Diagnostiquer les erreurs:"
echo "   journalctl -u logstash --since '5 minutes ago'"
echo "   sudo -u logstash /usr/share/logstash/bin/logstash -t"
echo ""

echo "3. VÃ©rifier les permissions:"
echo "   ls -la /etc/logstash/conf.d/"
echo "   chown -R logstash:logstash /etc/logstash/"
echo ""

# CrÃ©er un fichier de log d'installation
cat > /var/log/honeypot-pipeline-install.log << LOG_EOF
$(date): Installation pipeline Logstash corrigÃ© terminÃ©e
Sauvegarde: $BACKUP_DIR
Configuration: /etc/logstash/conf.d/00-honeypot-pipelines-corrected.conf
Outils: /opt/monitor_honeypot_corrected.sh, /opt/test_pipeline_corrected.sh
Status: SUCCESS
LOG_EOF

echo "ðŸ“ Log d'installation: /var/log/honeypot-pipeline-install.log"
echo ""

print_status "ðŸŽ‰ PIPELINE LOGSTASH CORRIGÃ‰ INSTALLÃ‰ AVEC SUCCÃˆS !"
echo ""
print_info "Votre infrastructure est maintenant prÃªte Ã  traiter correctement"
print_info "les logs Cowrie SSH et HTTP honeypot sans erreurs de parsing JSON."
echo ""
print_warning "N'oubliez pas d'installer Ã©galement le nouveau sender honeypot"
print_warning "pour une compatibilitÃ© parfaite avec ces pipelines !"
echo ""

# Test final automatique si demandÃ©
read -p "Voulez-vous exÃ©cuter un test automatique maintenant ? (y/n): " -n 1 -r
echo
if [[ $REPLY =~ ^[Yy]$ ]]; then
    echo ""
    print_status "ExÃ©cution du test automatique..."
    /opt/test_pipeline_corrected.sh
    echo ""
    print_status "Monitoring post-test..."
    /opt/monitor_honeypot_corrected.sh
fi

echo ""
print_status "Installation terminÃ©e - PrÃªt pour la production !"
echo ""

# Afficher le statut final
echo "=== STATUT FINAL ==="
echo "Logstash: $(systemctl is-active logstash)"
echo "Port 5046: $(netstat -tln | grep :5046 >/dev/null && echo 'OUVERT' || echo 'FERMÃ‰')"
echo "Elasticsearch: $(curl -s http://192.168.2.124:9200/_cluster/health | jq -r .status 2>/dev/null || echo 'INACCESSIBLE')"
echo "Configuration: /etc/logstash/conf.d/00-honeypot-pipelines-corrected.conf"
echo ""

exit 0